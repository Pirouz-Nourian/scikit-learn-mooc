{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,target=housing.data,housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.526\n",
       "1        3.585\n",
       "2        3.521\n",
       "3        3.413\n",
       "4        3.422\n",
       "         ...  \n",
       "20635    0.781\n",
       "20636    0.771\n",
       "20637    0.923\n",
       "20638    0.847\n",
       "20639    0.894\n",
       "Name: MedHouseVal, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4526000.0\n",
       "1        3585000.0\n",
       "2        3521000.0\n",
       "3        3413000.0\n",
       "4        3422000.0\n",
       "           ...    \n",
       "20635     781000.0\n",
       "20636     771000.0\n",
       "20637     923000.0\n",
       "20638     847000.0\n",
       "20639     894000.0\n",
       "Name: MedHouseVal, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target *=100\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "A decision tree regressor.\n",
      "\n",
      "Read more in the :ref:`User Guide <tree>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "criterion : {\"squared_error\", \"friedman_mse\", \"absolute_error\",             \"poisson\"}, default=\"squared_error\"\n",
      "    The function to measure the quality of a split. Supported criteria\n",
      "    are \"squared_error\" for the mean squared error, which is equal to\n",
      "    variance reduction as feature selection criterion and minimizes the L2\n",
      "    loss using the mean of each terminal node, \"friedman_mse\", which uses\n",
      "    mean squared error with Friedman's improvement score for potential\n",
      "    splits, \"absolute_error\" for the mean absolute error, which minimizes\n",
      "    the L1 loss using the median of each terminal node, and \"poisson\" which\n",
      "    uses reduction in Poisson deviance to find splits.\n",
      "\n",
      "    .. versionadded:: 0.18\n",
      "       Mean Absolute Error (MAE) criterion.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "        Poisson deviance criterion.\n",
      "\n",
      "splitter : {\"best\", \"random\"}, default=\"best\"\n",
      "    The strategy used to choose the split at each node. Supported\n",
      "    strategies are \"best\" to choose the best split and \"random\" to choose\n",
      "    the best random split.\n",
      "\n",
      "max_depth : int, default=None\n",
      "    The maximum depth of the tree. If None, then nodes are expanded until\n",
      "    all leaves are pure or until all leaves contain less than\n",
      "    min_samples_split samples.\n",
      "\n",
      "min_samples_split : int or float, default=2\n",
      "    The minimum number of samples required to split an internal node:\n",
      "\n",
      "    - If int, then consider `min_samples_split` as the minimum number.\n",
      "    - If float, then `min_samples_split` is a fraction and\n",
      "      `ceil(min_samples_split * n_samples)` are the minimum\n",
      "      number of samples for each split.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Added float values for fractions.\n",
      "\n",
      "min_samples_leaf : int or float, default=1\n",
      "    The minimum number of samples required to be at a leaf node.\n",
      "    A split point at any depth will only be considered if it leaves at\n",
      "    least ``min_samples_leaf`` training samples in each of the left and\n",
      "    right branches.  This may have the effect of smoothing the model,\n",
      "    especially in regression.\n",
      "\n",
      "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "    - If float, then `min_samples_leaf` is a fraction and\n",
      "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "      number of samples for each node.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Added float values for fractions.\n",
      "\n",
      "min_weight_fraction_leaf : float, default=0.0\n",
      "    The minimum weighted fraction of the sum total of weights (of all\n",
      "    the input samples) required to be at a leaf node. Samples have\n",
      "    equal weight when sample_weight is not provided.\n",
      "\n",
      "max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
      "    The number of features to consider when looking for the best split:\n",
      "\n",
      "    - If int, then consider `max_features` features at each split.\n",
      "    - If float, then `max_features` is a fraction and\n",
      "      `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      "      split.\n",
      "    - If \"auto\", then `max_features=n_features`.\n",
      "    - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "    - If \"log2\", then `max_features=log2(n_features)`.\n",
      "    - If None, then `max_features=n_features`.\n",
      "\n",
      "    .. deprecated:: 1.1\n",
      "        The `\"auto\"` option was deprecated in 1.1 and will be removed\n",
      "        in 1.3.\n",
      "\n",
      "    Note: the search for a split does not stop until at least one\n",
      "    valid partition of the node samples is found, even if it requires to\n",
      "    effectively inspect more than ``max_features`` features.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Controls the randomness of the estimator. The features are always\n",
      "    randomly permuted at each split, even if ``splitter`` is set to\n",
      "    ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
      "    select ``max_features`` at random at each split before finding the best\n",
      "    split among them. But the best found split may vary across different\n",
      "    runs, even if ``max_features=n_features``. That is the case, if the\n",
      "    improvement of the criterion is identical for several splits and one\n",
      "    split has to be selected at random. To obtain a deterministic behaviour\n",
      "    during fitting, ``random_state`` has to be fixed to an integer.\n",
      "    See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "max_leaf_nodes : int, default=None\n",
      "    Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      "    Best nodes are defined as relative reduction in impurity.\n",
      "    If None then unlimited number of leaf nodes.\n",
      "\n",
      "min_impurity_decrease : float, default=0.0\n",
      "    A node will be split if this split induces a decrease of the impurity\n",
      "    greater than or equal to this value.\n",
      "\n",
      "    The weighted impurity decrease equation is the following::\n",
      "\n",
      "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                            - N_t_L / N_t * left_impurity)\n",
      "\n",
      "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "    if ``sample_weight`` is passed.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "\n",
      "ccp_alpha : non-negative float, default=0.0\n",
      "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "    subtree with the largest cost complexity that is smaller than\n",
      "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "    :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "feature_importances_ : ndarray of shape (n_features,)\n",
      "    The feature importances.\n",
      "    The higher, the more important the feature.\n",
      "    The importance of a feature is computed as the\n",
      "    (normalized) total reduction of the criterion brought\n",
      "    by that feature. It is also known as the Gini importance [4]_.\n",
      "\n",
      "    Warning: impurity-based feature importances can be misleading for\n",
      "    high cardinality features (many unique values). See\n",
      "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "\n",
      "max_features_ : int\n",
      "    The inferred value of max_features.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_outputs_ : int\n",
      "    The number of outputs when ``fit`` is performed.\n",
      "\n",
      "tree_ : Tree instance\n",
      "    The underlying Tree object. Please refer to\n",
      "    ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      "    :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      "    for basic usage of these attributes.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DecisionTreeClassifier : A decision tree classifier.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The default values for the parameters controlling the size of the trees\n",
      "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "unpruned trees which can potentially be very large on some data sets. To\n",
      "reduce memory consumption, the complexity and size of the trees should be\n",
      "controlled by setting those parameter values.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      ".. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      "\n",
      ".. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      "       and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      "\n",
      ".. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      "       Learning\", Springer, 2009.\n",
      "\n",
      ".. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      "       https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import load_diabetes\n",
      ">>> from sklearn.model_selection import cross_val_score\n",
      ">>> from sklearn.tree import DecisionTreeRegressor\n",
      ">>> X, y = load_diabetes(return_X_y=True)\n",
      ">>> regressor = DecisionTreeRegressor(random_state=0)\n",
      ">>> cross_val_score(regressor, X, y, cv=10)\n",
      "...                    # doctest: +SKIP\n",
      "...\n",
      "array([-0.39..., -0.46...,  0.02...,  0.06..., -0.50...,\n",
      "       0.16...,  0.11..., -0.73..., -0.30..., -0.00...])\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\pirouz\\anaconda3\\envs\\scikit-learn-course\\lib\\site-packages\\sklearn\\tree\\_classes.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     ExtraTreeRegressor"
     ]
    }
   ],
   "source": [
    "?DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/classes.html\n",
    "\n",
    "regressor=DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=ShuffleSplit(n_splits=30,test_size=0.2)\n",
    "cv_results=cross_validate(\n",
    "    regressor,\n",
    "    data,\n",
    "    target,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    return_train_score=True, n_jobs=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.143784</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>-465631.225775</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145149</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>-457712.877907</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145643</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>-460588.616764</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.145268</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>-472170.518411</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142139</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>-456486.577035</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.143888</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>-450035.712209</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.137283</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>-462114.270833</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.141787</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>-465581.862888</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.145394</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>-458631.257267</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.142795</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>-461012.218992</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.144388</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>-444589.060078</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.150375</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>-475477.657461</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.175299</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>-465129.738372</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.167627</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>-457863.762112</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>-454005.261628</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.162919</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>-456245.113857</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.160870</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>-474959.711725</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.152278</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>-457413.236434</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.152279</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>-460632.916667</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.150481</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>-442766.392926</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.163027</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>-473691.724806</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.160517</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>-460313.837209</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.159261</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>-440293.742733</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.149548</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>-458550.554748</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.156669</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>-465048.347868</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.151389</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>-471656.397771</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.164064</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>-448014.743217</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.162875</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-435889.706880</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.152230</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>-456165.130814</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.145270</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>-448302.240795</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time     test_score  train_score\n",
       "0   0.143784    0.002699 -465631.225775         -0.0\n",
       "1   0.145149    0.003514 -457712.877907         -0.0\n",
       "2   0.145643    0.003149 -460588.616764         -0.0\n",
       "3   0.145268    0.002019 -472170.518411         -0.0\n",
       "4   0.142139    0.002506 -456486.577035         -0.0\n",
       "5   0.143888    0.002567 -450035.712209         -0.0\n",
       "6   0.137283    0.002506 -462114.270833         -0.0\n",
       "7   0.141787    0.002120 -465581.862888         -0.0\n",
       "8   0.145394    0.002006 -458631.257267         -0.0\n",
       "9   0.142795    0.002299 -461012.218992         -0.0\n",
       "10  0.144388    0.001999 -444589.060078         -0.0\n",
       "11  0.150375    0.003519 -475477.657461         -0.0\n",
       "12  0.175299    0.002013 -465129.738372         -0.0\n",
       "13  0.167627    0.003001 -457863.762112         -0.0\n",
       "14  0.173679    0.002014 -454005.261628         -0.0\n",
       "15  0.162919    0.002523 -456245.113857         -0.0\n",
       "16  0.160870    0.002000 -474959.711725         -0.0\n",
       "17  0.152278    0.002048 -457413.236434         -0.0\n",
       "18  0.152279    0.002571 -460632.916667         -0.0\n",
       "19  0.150481    0.002043 -442766.392926         -0.0\n",
       "20  0.163027    0.002537 -473691.724806         -0.0\n",
       "21  0.160517    0.002011 -460313.837209         -0.0\n",
       "22  0.159261    0.002466 -440293.742733         -0.0\n",
       "23  0.149548    0.002504 -458550.554748         -0.0\n",
       "24  0.156669    0.003007 -465048.347868         -0.0\n",
       "25  0.151389    0.002513 -471656.397771         -0.0\n",
       "26  0.164064    0.003195 -448014.743217         -0.0\n",
       "27  0.162875    0.000997 -435889.706880         -0.0\n",
       "28  0.152230    0.002751 -456165.130814         -0.0\n",
       "29  0.145270    0.002018 -448302.240795         -0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_error</th>\n",
       "      <th>test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>465631.225775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>457712.877907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>460588.616764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>472170.518411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>456486.577035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>450035.712209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>462114.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>465581.862888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>458631.257267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>461012.218992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>444589.060078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>475477.657461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>465129.738372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>457863.762112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>454005.261628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>456245.113857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>474959.711725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>457413.236434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>460632.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>442766.392926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>473691.724806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>460313.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>440293.742733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>458550.554748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>465048.347868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>471656.397771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>448014.743217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>435889.706880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>456165.130814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>448302.240795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_error     test_error\n",
       "0           0.0  465631.225775\n",
       "1           0.0  457712.877907\n",
       "2           0.0  460588.616764\n",
       "3           0.0  472170.518411\n",
       "4           0.0  456486.577035\n",
       "5           0.0  450035.712209\n",
       "6           0.0  462114.270833\n",
       "7           0.0  465581.862888\n",
       "8           0.0  458631.257267\n",
       "9           0.0  461012.218992\n",
       "10          0.0  444589.060078\n",
       "11          0.0  475477.657461\n",
       "12          0.0  465129.738372\n",
       "13          0.0  457863.762112\n",
       "14          0.0  454005.261628\n",
       "15          0.0  456245.113857\n",
       "16          0.0  474959.711725\n",
       "17          0.0  457413.236434\n",
       "18          0.0  460632.916667\n",
       "19          0.0  442766.392926\n",
       "20          0.0  473691.724806\n",
       "21          0.0  460313.837209\n",
       "22          0.0  440293.742733\n",
       "23          0.0  458550.554748\n",
       "24          0.0  465048.347868\n",
       "25          0.0  471656.397771\n",
       "26          0.0  448014.743217\n",
       "27          0.0  435889.706880\n",
       "28          0.0  456165.130814\n",
       "29          0.0  448302.240795"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[[\"train_error\",\"test_error\"]]=-cv_results[[\"train_score\",\"test_score\"]]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Frequency'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "scores.plot.hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=[1,5,10,15,20,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "# train_scores,test_scores=validation_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores,test_scores=validation_curve(\n",
    "    regressor,\n",
    "    data,\n",
    "    target,\n",
    "    param_name=\"max_depth\",\n",
    "    param_range=max_depth,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors,test_errors=-train_scores,-test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[742074.9971125 , 745532.90966302, 742100.01962794,\n",
       "        740796.89911751, 745565.43061232, 745282.15164856,\n",
       "        745742.64270276, 743320.99156375, 746384.9358975 ,\n",
       "        746290.79324542, 745422.93500286, 748978.72906156,\n",
       "        741941.13023361, 743085.27093755, 741603.07349324,\n",
       "        745576.17590444, 745155.69789945, 745497.62038812,\n",
       "        746349.75212232, 742118.8382065 , 745118.68257585,\n",
       "        748326.83779789, 746482.62398431, 746562.91424906,\n",
       "        746111.46697926, 742856.86176788, 746899.91143824,\n",
       "        743846.04962781, 741737.96077343, 746682.08735704],\n",
       "       [512641.62820682, 512952.81869774, 508421.60511982,\n",
       "        502827.019153  , 509873.57529281, 511623.08778473,\n",
       "        509842.43388018, 501840.8308823 , 513212.97749595,\n",
       "        509884.15425136, 507685.75367518, 503064.19674068,\n",
       "        514715.64387644, 508105.55859272, 506205.43294143,\n",
       "        506003.86543087, 506293.63417896, 503602.94915355,\n",
       "        510037.89611877, 510158.68124697, 513204.53497893,\n",
       "        513150.83618199, 512696.20730982, 512473.11008775,\n",
       "        514190.08313922, 503099.05715197, 505206.09425777,\n",
       "        509817.02053125, 511397.98564779, 504833.06371629],\n",
       "       [317072.68410576, 320222.26713664, 317184.9991235 ,\n",
       "        319743.74475017, 321376.40364556, 325483.56827251,\n",
       "        316665.61809083, 310458.63993068, 315322.46188004,\n",
       "        320514.74188346, 314273.38525798, 309012.6074605 ,\n",
       "        319007.81239126, 333141.16631099, 322434.21150006,\n",
       "        309398.34469326, 317151.42250104, 309000.5534484 ,\n",
       "        326888.39867486, 320021.36696972, 325215.03937932,\n",
       "        318400.452438  , 326325.70640252, 320303.56398929,\n",
       "        314101.97001106, 306244.07865694, 316358.11127174,\n",
       "        334203.88342708, 320710.22386246, 314859.34404384],\n",
       "       [120900.4792706 , 118528.17544515, 119186.02351227,\n",
       "        121869.88536439, 120267.07824892, 129877.82009123,\n",
       "        123118.68529001, 122570.14068865, 114842.51883579,\n",
       "        112034.04457847, 120379.57642342, 119962.07912938,\n",
       "        119719.92053037, 124490.17660014, 123532.71544084,\n",
       "        122934.01476844, 124148.99694493, 119753.86605499,\n",
       "        130218.57201081, 121305.13671203, 124098.24545743,\n",
       "        124250.81433831, 123519.95792975, 117935.48452558,\n",
       "        116097.54520517, 121152.05710208, 127110.61641332,\n",
       "        126465.33983888, 121922.36450046, 125430.99911842],\n",
       "       [ 22344.28895912,  21735.94124611,  23351.60516486,\n",
       "         24762.26753597,  20757.88820327,  25483.53390313,\n",
       "         20768.71017439,  27703.33986508,  21221.90114979,\n",
       "         19902.19617062,  22585.88874581,  23192.04049979,\n",
       "         20587.92679687,  24228.38688439,  21615.87058951,\n",
       "         24201.78745137,  25257.95736868,  23570.51885539,\n",
       "         27065.67214539,  20544.22775636,  23035.60153417,\n",
       "         23619.51635253,  21517.20695931,  22516.63883403,\n",
       "         20377.83148748,  23738.16672868,  25957.81264204,\n",
       "         23356.31274849,  21321.63210603,  24699.14314465],\n",
       "       [  1753.39492348,   1301.26317246,   2603.73464456,\n",
       "          2523.8070876 ,   2022.69447711,   2046.49087853,\n",
       "          1385.29271621,   2838.06026144,   2080.34825518,\n",
       "          1984.01595103,   1882.98926163,   1885.31114309,\n",
       "          1335.5530754 ,   2319.3037358 ,   1791.18954243,\n",
       "          1978.90494032,   2478.26339932,   2809.92533469,\n",
       "          4070.28191971,   1259.96950913,   2090.65995931,\n",
       "          2658.94746815,   2490.89885382,   1889.77480933,\n",
       "          1660.77390424,   1924.59065177,   2876.37462394,\n",
       "          1980.65998487,   1669.40575205,   1756.17729062]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39;49merrorbar(max_depth,train_errors)\n",
      "File \u001b[1;32mc:\\Users\\Pirouz\\anaconda3\\envs\\scikit-learn-course\\Lib\\site-packages\\matplotlib\\pyplot.py:2500\u001b[0m, in \u001b[0;36merrorbar\u001b[1;34m(x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, data, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39merrorbar)\n\u001b[0;32m   2495\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorbar\u001b[39m(\n\u001b[0;32m   2496\u001b[0m         x, y, yerr\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, xerr\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, ecolor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2497\u001b[0m         elinewidth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, capsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, barsabove\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, lolims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   2498\u001b[0m         uplims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, xlolims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, xuplims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, errorevery\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   2499\u001b[0m         capthick\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2500\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49merrorbar(\n\u001b[0;32m   2501\u001b[0m         x, y, yerr\u001b[39m=\u001b[39;49myerr, xerr\u001b[39m=\u001b[39;49mxerr, fmt\u001b[39m=\u001b[39;49mfmt, ecolor\u001b[39m=\u001b[39;49mecolor,\n\u001b[0;32m   2502\u001b[0m         elinewidth\u001b[39m=\u001b[39;49melinewidth, capsize\u001b[39m=\u001b[39;49mcapsize, barsabove\u001b[39m=\u001b[39;49mbarsabove,\n\u001b[0;32m   2503\u001b[0m         lolims\u001b[39m=\u001b[39;49mlolims, uplims\u001b[39m=\u001b[39;49muplims, xlolims\u001b[39m=\u001b[39;49mxlolims,\n\u001b[0;32m   2504\u001b[0m         xuplims\u001b[39m=\u001b[39;49mxuplims, errorevery\u001b[39m=\u001b[39;49merrorevery, capthick\u001b[39m=\u001b[39;49mcapthick,\n\u001b[0;32m   2505\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Pirouz\\anaconda3\\envs\\scikit-learn-course\\Lib\\site-packages\\matplotlib\\__init__.py:1433\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1431\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1432\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1433\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1435\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1436\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1437\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\Pirouz\\anaconda3\\envs\\scikit-learn-course\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:3508\u001b[0m, in \u001b[0;36mAxes.errorbar\u001b[1;34m(self, x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, **kwargs)\u001b[0m\n\u001b[0;32m   3502\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_nolegend_\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   3504\u001b[0m \u001b[39m# Create the main line and determine overall kwargs for child artists.\u001b[39;00m\n\u001b[0;32m   3505\u001b[0m \u001b[39m# We avoid calling self.plot() directly, or self._get_lines(), because\u001b[39;00m\n\u001b[0;32m   3506\u001b[0m \u001b[39m# that would call self._process_unit_info again, and do other indirect\u001b[39;00m\n\u001b[0;32m   3507\u001b[0m \u001b[39m# data processing.\u001b[39;00m\n\u001b[1;32m-> 3508\u001b[0m (data_line, base_style), \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines\u001b[39m.\u001b[39m_plot_args(\n\u001b[0;32m   3509\u001b[0m     (x, y) \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m (x, y, fmt), kwargs, return_kwargs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   3511\u001b[0m \u001b[39m# Do this after creating `data_line` to avoid modifying `base_style`.\u001b[39;00m\n\u001b[0;32m   3512\u001b[0m \u001b[39mif\u001b[39;00m barsabove:\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 1)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(max_depth,train_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([744781.54636639, 508968.7245241 , 318703.22571698, 121920.77767901,\n",
       "        23034.06040011,   2111.63525091])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_errors.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2098.40197658, 3795.12212501, 6532.75592081, 3911.44939097,\n",
       "       1999.77363806,  577.05797074])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_errors.std(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-learn-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27b26e275e4136e28dc2ad937f9c072e10e8a0b1e9b90b40146ce03199647dbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
